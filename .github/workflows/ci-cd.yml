name: "‚è∞ Scheduler Backend - CI/CD Pipeline"

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

# Controle de concorr√™ncia para evitar execu√ß√µes simult√¢neas
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Vari√°veis de ambiente global
env:
  SERVICE_NAME: scheduler-backend
  STACK_NAME: conexao-scheduler
  DOCKER_NETWORK_NAME: conexao-network-swarm

permissions:
  id-token: write    # Necess√°rio para OIDC com Azure (azure/login@v2)
  contents: read     # Necess√°rio para checkout em jobs

jobs:
  validate-and-build:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read
      id-token: write
    outputs:
      has_keyvault: ${{ steps.check_secrets.outputs.has_keyvault }}
      has_azure_creds: ${{ steps.check_secrets.outputs.has_azure_creds }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4.3.0
        with:
          fetch-depth: 1

      - name: Set up JDK 25
        uses: actions/setup-java@v4
        with:
          java-version: '25'
          distribution: 'liberica'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y python3 python3-yaml jq

      - name: Validate Docker Compose
        run: |
          docker compose -f docker-compose.yml config -q
          echo "‚úÖ Docker Compose syntax is valid"

      - name: Security Validation - No Hardcoded Passwords
        run: |
          # Verificar se n√£o h√° hardcoded passwords
          if grep -r "password.*:" docker-compose.yml pom.xml | grep -v "\${" | grep -v "#" | grep -v "external:"; then
            echo "‚ùå Found potential hardcoded passwords"
            exit 1
          else
            echo "‚úÖ No hardcoded passwords found"
          fi

      - name: Guard - Proibir r2dbc:h2 fora de testes
        run: |
          set -euo pipefail
          FOUND=$(grep -R --line-number --include='*.yml' --include='*.yaml' --include='*.properties' "r2dbc:h2" src || true)
          if [[ -n "$FOUND" ]]; then
            echo "‚ùå H2 database encontrado fora de testes:"
            echo "$FOUND"
            echo "üîß Solu√ß√£o: use MySQL/PostgreSQL em produ√ß√£o"
            exit 1
          else
            echo "‚úÖ Nenhum r2dbc:h2 encontrado em produ√ß√£o"
          fi

      - name: üîé Validar OIDC Azure
        id: check_secrets
        env:
          AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          AZURE_KEYVAULT_NAME: ${{ secrets.AZURE_KEYVAULT_NAME }}
          AZURE_KEYVAULT_ENDPOINT: ${{ secrets.AZURE_KEYVAULT_ENDPOINT }}
        run: |
          set -Eeuo pipefail
          missing=()
          for var in AZURE_CLIENT_ID AZURE_TENANT_ID AZURE_SUBSCRIPTION_ID; do
            if [[ -z "${!var:-}" ]]; then
              missing+=("$var")
            fi
          done
          if (( ${#missing[@]} )); then
            printf '‚ùå GitHub Secrets obrigat√≥rios ausentes: %s\n' "${missing[*]}"
            exit 1
          fi
          echo "‚úÖ Identificadores Azure configurados via secrets"

          # Key Vault √© opcional
          if [[ -n "${AZURE_KEYVAULT_NAME:-}" ]]; then
            echo "has_keyvault=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_keyvault=false" >> "$GITHUB_OUTPUT"
          fi

          if [[ -z "${AZURE_KEYVAULT_ENDPOINT:-}" ]]; then
            echo '‚ÑπÔ∏è AZURE_KEYVAULT_ENDPOINT n√£o definido (usando endpoint padr√£o)'
          else
            echo '‚úÖ Endpoint customizado definido'
          fi

          echo "has_azure_creds=true" >> "$GITHUB_OUTPUT"

      - name: Validate Maven Project
        run: |
          if [ -f "pom.xml" ]; then
            echo "‚úÖ Projeto Maven detectado"
            mvn validate
            echo "‚úÖ Maven project validation passed"
          else
            echo "‚ÑπÔ∏è Projeto n√£o-Maven (sem pom.xml)"
          fi

      - name: Validate YAML files
        run: |
          python3 -c "
          import yaml
          import pathlib

          # Validar arquivos YAML principais
          yaml_files = [
              'docker-compose.yml'
          ]

          for file_path in yaml_files:
              if pathlib.Path(file_path).exists():
                  try:
                      with open(file_path, 'r', encoding='utf-8') as f:
                          yaml.safe_load(f)
                      print(f'‚úÖ YAML v√°lido: {file_path}')
                  except Exception as e:
                      print(f'‚ùå Erro no YAML {file_path}: {e}')
                      exit(1)
          "

      - name: ‚úÖ Confirmar consumo m√≠nimo do Key Vault
        if: ${{ steps.check_secrets.outputs.has_keyvault == 'true' }}
        run: |
          echo 'Job de valida√ß√£o n√£o consome segredos do Key Vault (lista vazia).'
          echo "‚úÖ Valida√ß√£o de Key Vault conclu√≠da sem consumo de segredos"

      - name: Validation completed
        run: |
          echo "‚úÖ Valida√ß√£o conclu√≠da - pronto para deploy"

  deploy-selfhosted:
    needs: validate-and-build
    runs-on: [self-hosted, Linux, X64, conexao, conexao-de-sorte-backend-scheduler]
    timeout-minutes: 20
    if: github.ref == 'refs/heads/main'
    permissions:
      contents: read
      id-token: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4.3.0
        with:
          clean: true
          fetch-depth: 1

      - name: üîê Azure Login (OIDC)
        if: ${{ needs.validate-and-build.outputs.has_azure_creds == 'true' }}
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: ‚úÖ Validar conex√£o Azure (OIDC)
        if: ${{ needs.validate-and-build.outputs.has_azure_creds == 'true' }}
        run: |
          echo "üîç Validando conex√£o com Azure via OIDC..."
          if az account show >/dev/null 2>&1; then
            echo "‚úÖ Conex√£o Azure OIDC estabelecida"
            echo "Subscription: $(az account show --query id -o tsv)"
          else
            echo "‚ùå Falha na conex√£o Azure OIDC"
            exit 1
          fi

      - name: üîí Security Validation - Port Exposure
        run: |
          # Verificar exposi√ß√£o de portas do Scheduler
          if grep -E "^\s*-\s*[\"']?(8084|8085|8086):" docker-compose.yml; then
            echo "‚ö†Ô∏è WARNING: Scheduler ports may be exposed - ensure firewall protection"
            echo "üîí Note: Current configuration works but consider overlay-only for maximum security"
          else
            echo "‚úÖ No ports exposed - maximum security (overlay network only)"
          fi

      - name: üîê Get secrets from Azure Key Vault
        run: |
          # Usar endpoint do Key Vault se dispon√≠vel, sen√£o usar nome
          KEYVAULT_ENDPOINT="${{ secrets.AZURE_KEYVAULT_ENDPOINT }}"
          if [[ -n "$KEYVAULT_ENDPOINT" ]]; then
            # Extrair o nome do Key Vault do endpoint (formato: `https://nome-do-keyvault.vault.azure.net/)`
            KEYVAULT_NAME=$(echo "$KEYVAULT_ENDPOINT" | sed 's|https://\(.*\)\.vault\.azure\.net/.*|\1|')
            echo "üîë Usando Key Vault do endpoint: $KEYVAULT_NAME"
          else
            KEYVAULT_NAME="${{ secrets.AZURE_KEYVAULT_NAME }}"
            echo "üîë Usando Key Vault do nome: $KEYVAULT_NAME"
          fi
          
          # Usar Azure CLI diretamente para obter segredos
          echo "üîç Obtendo segredos do Key Vault: $KEYVAULT_NAME"
          
          secrets_list="conexao-de-sorte-database-r2dbc-url,conexao-de-sorte-database-username,conexao-de-sorte-database-password,conexao-de-sorte-redis-host,conexao-de-sorte-redis-port,conexao-de-sorte-redis-password,conexao-de-sorte-redis-database,conexao-de-sorte-rabbitmq-host,conexao-de-sorte-rabbitmq-port,conexao-de-sorte-rabbitmq-username,conexao-de-sorte-rabbitmq-password,conexao-de-sorte-rabbitmq-vhost,conexao-de-sorte-jwt-secret,conexao-de-sorte-jwt-issuer,conexao-de-sorte-jwt-signing-key,conexao-de-sorte-jwt-verification-key,conexao-de-sorte-server-port"
          
          IFS=',' read -ra SECRETS_ARRAY <<< "$secrets_list"
          for secret_name in "${SECRETS_ARRAY[@]}"; do
            echo "üîç Obtendo segredo: $secret_name"
            secret_value=$(az keyvault secret show --vault-name "$KEYVAULT_NAME" --name "$secret_name" --query 'value' -o tsv 2>/dev/null || echo "")
            
            if [[ -n "$secret_value" ]]; then
              echo "‚úÖ Segredo obtido: $secret_name"
              # Salvar com o nome original (com tra√ßos) para compatibilidade com o step de valida√ß√£o
              echo "${secret_name}=${secret_value}" >> $GITHUB_OUTPUT
              # Tamb√©m salvar como vari√°vel de ambiente para uso posterior
              env_var_name=$(echo "$secret_name" | tr '-' '_' | tr '[:lower:]' '[:upper:]')
              echo "${env_var_name}=${secret_value}" >> $GITHUB_ENV
            else
              echo "‚ö†Ô∏è Segredo n√£o encontrado: $secret_name"
            fi
          done
          
          echo "‚úÖ Obten√ß√£o de segredos conclu√≠da"
        shell: /usr/bin/bash -e {0}
        env:
          SERVICE_NAME: scheduler
          STACK_NAME: conexao-scheduler
          DOCKER_NETWORK_NAME: conexao-network-swarm
        id: kv

      - name: üîí Mask sensitive values
        run: |
          echo ::add-mask::"${{ steps.kv.outputs.conexao-de-sorte-database-password }}"
          echo ::add-mask::"${{ steps.kv.outputs.conexao-de-sorte-redis-password }}"
          echo ::add-mask::"${{ steps.kv.outputs.conexao-de-sorte-rabbitmq-password }}"
          echo ::add-mask::"${{ steps.kv.outputs.conexao-de-sorte-jwt-secret }}"
          echo ::add-mask::"${{ steps.kv.outputs.conexao-de-sorte-jwt-signing-key }}"

      - name: üåê Preparar rede overlay compartilhada
        env:
          NETWORK_NAME: ${{ env.DOCKER_NETWORK_NAME }}
        run: |
          set -euo pipefail
          echo "üîç Verificando rede overlay: $NETWORK_NAME"

          if ! docker network inspect "$NETWORK_NAME" >/dev/null 2>&1; then
            echo "üèóÔ∏è Criando rede overlay compartilhada: $NETWORK_NAME"
            docker network create \
              --driver overlay \
              --attachable \
              --subnet=10.10.0.0/16 \
              --gateway=10.10.0.1 \
              "${NETWORK_NAME}"
            echo "‚úÖ Rede overlay criada: $NETWORK_NAME"
          else
            echo "‚úÖ Rede overlay j√° existe: $NETWORK_NAME"
          fi

      - name: üßπ Cleanup anterior (Scheduler)
        env:
          STACK_NAME: ${{ env.STACK_NAME }}
        run: |
          set -euo pipefail
          echo "üßπ Iniciando limpeza de recursos anteriores..."

          # 1. Graceful shutdown: scale services to 0 replicas
          if docker service ls --filter name="$STACK_NAME" --format '{{.Name}}' | grep -q "^$STACK_NAME"; then
            echo "üîÑ Scaling down servi√ßos do stack $STACK_NAME..."
            for service in $(docker service ls --filter name="$STACK_NAME" --format '{{.Name}}'); do
              echo "  - Scaling down: $service"
              docker service scale "$service=0" >/dev/null 2>&1 || true
            done
            sleep 10
          fi

          # 2. Remove stack
          if docker stack ls --format '{{.Name}}' | grep -q "^$STACK_NAME\$"; then
            echo "üóÑÔ∏è Removendo stack: $STACK_NAME"
            docker stack rm "$STACK_NAME"
            sleep 15
          fi

          # 3. Clean orphan containers
          echo "üßπ Limpando containers √≥rf√£os relacionados ao Scheduler..."
          orphan_containers=$(docker ps -a --filter name="*scheduler*" --format '{{.ID}} {{.Names}}' | grep -E "(scheduler|$STACK_NAME)" || true)
          if [[ -n "$orphan_containers" ]]; then
            echo "$orphan_containers" | while read container_id container_name; do
              if [[ -n "$container_id" ]]; then
                echo "  üóëÔ∏è Removendo container √≥rf√£o: $container_name ($container_id)"
                docker stop "$container_id" >/dev/null 2>&1 || true
                docker rm "$container_id" >/dev/null 2>&1 || true
              fi
            done
          fi

          # 4. Image cleanup (keep 3 recent versions)
          echo "üßπ Limpando imagens antigas do Scheduler (mantendo 3 vers√µes recentes)..."
          old_images=$(docker images --format "{{.ID}} {{.Repository}}:{{.Tag}}" | grep -E "(scheduler|ghcr.io.*scheduler)" | tail -n +4 || true)
          if [[ -n "$old_images" ]]; then
            echo "$old_images" | while read image_id image_tag; do
              if [[ -n "$image_id" && "$image_tag" != *"<none>"* ]]; then
                echo "  üóëÔ∏è Removendo imagem antiga: $image_tag ($image_id)"
                docker rmi "$image_id" >/dev/null 2>&1 || true
              fi
            done
          fi

          echo "‚úÖ Limpeza conclu√≠da"

      - name: üöÄ Deploy Scheduler Stack (Swarm-Only)
        env:
          STACK_NAME: ${{ env.STACK_NAME }}
          COMPOSE_FILE: docker-compose.yml
          # Banco de Dados
          CONEXAO_DE_SORTE_DATABASE_R2DBC_URL: ${{ steps.kv.outputs.conexao-de-sorte-database-r2dbc-url }}
          CONEXAO_DE_SORTE_DATABASE_USERNAME: ${{ steps.kv.outputs.conexao-de-sorte-database-username }}
          CONEXAO_DE_SORTE_DATABASE_PASSWORD: ${{ steps.kv.outputs.conexao-de-sorte-database-password }}
          # Redis
          CONEXAO_DE_SORTE_REDIS_HOST: ${{ steps.kv.outputs.conexao-de-sorte-redis-host }}
          CONEXAO_DE_SORTE_REDIS_PORT: ${{ steps.kv.outputs.conexao-de-sorte-redis-port }}
          CONEXAO_DE_SORTE_REDIS_PASSWORD: ${{ steps.kv.outputs.conexao-de-sorte-redis-password }}
          CONEXAO_DE_SORTE_REDIS_DATABASE: ${{ steps.kv.outputs.conexao-de-sorte-redis-database }}
          # RabbitMQ
          CONEXAO_DE_SORTE_RABBITMQ_HOST: ${{ steps.kv.outputs.conexao-de-sorte-rabbitmq-host }}
          CONEXAO_DE_SORTE_RABBITMQ_PORT: ${{ steps.kv.outputs.conexao-de-sorte-rabbitmq-port }}
          CONEXAO_DE_SORTE_RABBITMQ_USERNAME: ${{ steps.kv.outputs.conexao-de-sorte-rabbitmq-username }}
          CONEXAO_DE_SORTE_RABBITMQ_PASSWORD: ${{ steps.kv.outputs.conexao-de-sorte-rabbitmq-password }}
          CONEXAO_DE_SORTE_RABBITMQ_VHOST: ${{ steps.kv.outputs.conexao-de-sorte-rabbitmq-vhost }}
          # JWT
          CONEXAO_DE_SORTE_JWT_SECRET: ${{ steps.kv.outputs.conexao-de-sorte-jwt-secret }}
          CONEXAO_DE_SORTE_JWT_ISSUER: ${{ steps.kv.outputs.conexao-de-sorte-jwt-issuer }}
          CONEXAO_DE_SORTE_JWT_SIGNING_KEY: ${{ steps.kv.outputs.conexao-de-sorte-jwt-signing-key }}
          CONEXAO_DE_SORTE_JWT_VERIFICATION_KEY: ${{ steps.kv.outputs.conexao-de-sorte-jwt-verification-key }}
          # Server
          CONEXAO_DE_SORTE_SERVER_PORT: ${{ steps.kv.outputs.conexao-de-sorte-server-port }}
        run: |
          echo "üöÄ Iniciando deploy do Scheduler com Docker Swarm..."

          echo "üèóÔ∏è Executando deploy da stack '$STACK_NAME'..."
          docker stack deploy -c "$COMPOSE_FILE" "$STACK_NAME"

          echo "‚è∞ Aguardando estabiliza√ß√£o dos servi√ßos Scheduler..."
          sleep 35

      - name: üîç Healthcheck Scheduler
        env:
          STACK_NAME: ${{ env.STACK_NAME }}
        run: |
          echo "üîç Validando sa√∫de do Scheduler..."

          timeout=200
          elapsed=0
          health_passed=false

          while [ $elapsed -lt $timeout ] && [ "$health_passed" = false ]; do
            SCHEDULER_CONTAINER=$(docker ps -q -f name="${STACK_NAME}_scheduler" | head -1)

            if [ -n "$SCHEDULER_CONTAINER" ]; then
              echo "üîç Testando health check do Scheduler... ($elapsed/$timeout segundos)"

              # Check 1: Process validation
              if docker exec "$SCHEDULER_CONTAINER" ps aux 2>/dev/null | grep -q "[j]ava\|[s]pring"; then
                echo "‚úÖ Scheduler health check passed (process validation)"
                health_passed=true
                break
              fi

              # Check 2: Log validation
              if docker logs "$SCHEDULER_CONTAINER" 2>/dev/null | grep -q "Started.*Application\|Tomcat started\|Started SchedulerApplication"; then
                echo "‚úÖ Scheduler health check passed (logs validation)"
                health_passed=true
                break
              fi

              echo "‚è≥ Scheduler ainda n√£o est√° pronto... ($elapsed/$timeout segundos)"
            else
              echo "‚è≥ Container Scheduler ainda n√£o encontrado... ($elapsed/$timeout segundos)"
            fi

            sleep 10
            elapsed=$((elapsed + 10))
          done

          if [ "$health_passed" = false ]; then
            echo "‚ö†Ô∏è Scheduler health check n√£o passou em $timeout segundos"
            echo "üîç Verificando logs finais do Scheduler..."
            if [ -n "$SCHEDULER_CONTAINER" ]; then
              echo "--- √öltimos 30 logs do Scheduler ---"
              docker logs "$SCHEDULER_CONTAINER" --tail 30 2>/dev/null || true
              echo "--- Fim dos logs ---"
            fi
            echo "üí° Nota: Scheduler pode estar funcionando mesmo com health check parcial"
            exit 1
          else
            echo "‚úÖ Scheduler health check conclu√≠do com sucesso!"
          fi

      - name: üîó Connectivity Validation
        env:
          STACK_NAME: ${{ env.STACK_NAME }}
          DOCKER_NETWORK_NAME: ${{ env.DOCKER_NETWORK_NAME }}
        run: |
          echo "üîó Validando conectividade do Scheduler..."

          if docker service ls | grep -q "${STACK_NAME}_scheduler"; then
            echo "‚úÖ Servi√ßo Scheduler encontrado no Swarm"
          else
            echo "‚ùå Servi√ßo Scheduler n√£o encontrado no Swarm"
            exit 1
          fi

          if docker network inspect "$DOCKER_NETWORK_NAME" | grep -q scheduler; then
            echo "‚úÖ Scheduler conectado √† rede overlay"
          else
            echo "‚ö†Ô∏è Scheduler pode n√£o estar na rede overlay correta"
          fi

          echo "üìä Status final dos servi√ßos:"
          docker service ls --filter name="${STACK_NAME}_*" --format "table {{.Name}}\t{{.Replicas}}\t{{.Image}}"

      - name: üè• Validar Health Monitor (Traefik)
        env:
          HEALTH_MONITOR_URL: https://traefik.conexaodesorte.com.br/health/service/scheduler
        run: |
          set -euo pipefail
          timeout=300
          interval=10
          elapsed=0
          last_response=""

          while [ $elapsed -lt $timeout ]; do
            echo "üîé Consultando Health Monitor (${elapsed}/${timeout}s)..."
            response=$(curl -sf --max-time 10 "$HEALTH_MONITOR_URL" 2>/dev/null || true)
            last_response="$response"

            if [[ -n "$response" ]]; then
              status=$(echo "$response" | jq -r '.status // "unknown"' 2>/dev/null || echo "unknown")
              status=${status//$'\n'/}
              echo "üìä Status reportado pelo monitor: ${status:-indefinido}"

              if [[ "$status" == "healthy" ]]; then
                echo "‚úÖ Traefik confirmou Scheduler como healthy"
                exit 0
              fi
            else
              echo "‚ö†Ô∏è Health Monitor sem resposta (tentativa atual)"
            fi

            sleep "$interval"
            elapsed=$((elapsed + interval))
          done

          echo "‚ùå Health Monitor nao confirmou Scheduler como healthy apos ${timeout}s"
          echo "üìù Ultima resposta recebida: ${last_response:-<sem resposta>}"
          exit 1

      - name: üßº Limpeza de recursos no servidor
        if: success()
        env:
          STACK_NAME: ${{ env.STACK_NAME }}
        run: |
          set -euo pipefail
          before_usage=$(mktemp)
          after_usage=$(mktemp)
          docker system df > "$before_usage"
          echo "üßπ Removendo containers parados (‚â•12h)..."
          docker container prune -f --filter "until=12h"
          echo "üßπ Removendo imagens n√£o utilizadas (‚â•7d)..."
          docker image prune -f --filter "until=168h"
          echo "üßπ Removendo caches de build antigos (‚â•7d)..."
          docker builder prune -f --filter "until=168h" || true
          docker system df > "$after_usage"
          echo "üì¶ Uso de recursos ap√≥s limpeza:"
          cat "$after_usage"
          {
            echo "## Limpeza de recursos no servidor"
            echo ""
            echo "### Uso antes"
            sed 's/^/    /' "$before_usage"
            echo ""
            echo "### Uso depois"
            sed 's/^/    /' "$after_usage"
          } >> "$GITHUB_STEP_SUMMARY"
          rm -f "$before_usage" "$after_usage"
